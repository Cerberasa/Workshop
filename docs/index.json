[{"uri":"https://cerberasa.github.io/Workshop/","title":" 1.Introduction","tags":[],"description":"","content":"Overview In the context of rapidly developing cloud computing infrastructure, businesses and software development teams are increasingly focused on optimizing performance, operating costs, and energy sustainability.\nThe two main hardware architectures currently on AWS are:\n x86 (Intel/AMD): the traditional standard, with a broad software ecosystem and strong compatibility with legacy applications. ARM (AWS Graviton): uses the RISC instruction set, optimized for performance per watt, consumes less power, and can reduce operating costs by up to 40% compared to x86 in many cases.  However, deploying and managing applications for both architectures at the same time often comes with challenges:\n Requires separate image builds for each architecture. Requires multi-architecture testing environments. Requires automated pipelines to avoid manual errors and save time.  This workshop will guide you in building a multi-architecture CI/CD pipeline to deploy a sample application on both ARM and x86 automatically.\nThe outcome will help you decide whether to migrate workloads to ARM or stay on x86 based on real experimental data rather than assumptions.\n The system consists of the following main components:  Amazon EC2 (t4g.micro – ARM, t3.micro – x86): provides virtual servers on two different architectures for deploying and testing applications. Amazon ECR (Elastic Container Registry): stores multi-architecture Docker images for easy distribution to both ARM and x86. AWS IAM (Identity and Access Management): manages access control and security for the pipeline, ECR, and EC2. AWS VPC (Virtual Private Cloud): provides a private network, securing the deployment and testing environment. AWS CodePipeline / CodeBuild: AWS native CI/CD services for automatically building, testing, and deploying multi-architecture images. AWS ECR Multi-Arch Build Support: replaces Docker Buildx, using native AWS services to build images for both ARM and x86 from the same codebase.   The system is designed to:  Save up to 40% in operating costs when using ARM for suitable workloads. Automate the build and deployment process for both architectures, reducing manual errors and saving time. Ensure compatibility through multi-architecture testing before moving to production. Compare costs and energy consumption to optimize deployment strategy.   Multi-architecture deployment allows you to fully leverage the strengths of each hardware platform. ARM is suitable for workloads optimized for cost and energy efficiency, while x86 ensures compatibility with legacy software and stable environments.\n  Main contents  Introduction Prepare AWS environment (EC2 ARM \u0026amp; x86) Prepare source code repository and clone sample repo Install tools and configure AWS CLI, CDK Deploy pipeline using CDK Deploy application to ARM and x86 EC2 Clean up resources  "},{"uri":"https://cerberasa.github.io/Workshop/introduction/","title":" 1.Introduction","tags":[],"description":"","content":"Overview In the context of rapidly developing cloud computing infrastructure, businesses and software development teams are increasingly focused on optimizing performance, operating costs, and energy sustainability.\nThe two main hardware architectures currently on AWS are:\n x86 (Intel/AMD): the traditional standard, with a broad software ecosystem and strong compatibility with legacy applications. ARM (AWS Graviton): uses the RISC instruction set, optimized for performance per watt, consumes less power, and can reduce operating costs by up to 40% compared to x86 in many cases.  However, deploying and managing applications for both architectures at the same time often comes with challenges:\n Requires separate image builds for each architecture. Requires multi-architecture testing environments. Requires automated pipelines to avoid manual errors and save time.  This workshop will guide you in building a multi-architecture CI/CD pipeline to deploy a sample application on both ARM and x86 automatically.\nThe outcome will help you decide whether to migrate workloads to ARM or stay on x86 based on real experimental data rather than assumptions.\n The system consists of the following main components:  Amazon EC2 (t4g.micro – ARM, t3.micro – x86): provides virtual servers on two different architectures for deploying and testing applications. Amazon ECR (Elastic Container Registry): stores multi-architecture Docker images for easy distribution to both ARM and x86. AWS IAM (Identity and Access Management): manages access control and security for the pipeline, ECR, and EC2. AWS VPC (Virtual Private Cloud): provides a private network, securing the deployment and testing environment. AWS CodePipeline / CodeBuild: AWS native CI/CD services for automatically building, testing, and deploying multi-architecture images. AWS ECR Multi-Arch Build Support: replaces Docker Buildx, using native AWS services to build images for both ARM and x86 from the same codebase.   The system is designed to:  Save up to 40% in operating costs when using ARM for suitable workloads. Automate the build and deployment process for both architectures, reducing manual errors and saving time. Ensure compatibility through multi-architecture testing before moving to production. Compare costs and energy consumption to optimize deployment strategy.   Multi-architecture deployment allows you to fully leverage the strengths of each hardware platform. ARM is suitable for workloads optimized for cost and energy efficiency, while x86 ensures compatibility with legacy software and stable environments.\n  Main contents  Introduction Prepare AWS environment (EC2 ARM \u0026amp; x86) Prepare source code repository and clone sample repo Install tools and configure AWS CLI, CDK Deploy pipeline using CDK Deploy application to ARM and x86 EC2 Clean up resources  "},{"uri":"https://cerberasa.github.io/Workshop/ec2/","title":"2. Prepare AWS Environment (EC2 ARM &amp; x86)","tags":[],"description":"","content":"Objective Create two EC2 instances with ARM and x86 architectures to serve deployment and testing purposes.\nIncludes configuring VPC and Subnet if not already available.\n 2.1 Access AWS Management Console  Open your browser and go to: https://aws.amazon.com/console/ Log in with your AWS account.   2.2 Check or create new VPC \u0026amp; Subnet 2.2.1 Check existing VPC  In AWS Console, go to the VPC service: https://console.aws.amazon.com/vpc/ Select Your VPCs from the left menu. If a default VPC exists → you can use it directly. If you want to create a new one → follow step 2.2.2.  2.2.2 Create a new VPC  Click Create VPC.  Select VPC only. Name it (e.g., workshop-vpc). IPv4 CIDR block: 10.0.0.0/16 Keep other options as default → Create VPC.   2.2.3 Create Subnet for new VPC  Go to Subnets → Create subnet. Select the VPC you just created (workshop-vpc). Name the subnet (e.g., workshop-subnet-public). Choose Availability Zone (e.g., ap-southeast-1a). IPv4 CIDR block: 10.0.1.0/24 Create subnet.  Change the Subnet to Auto-assign Public IPv4 mode:  Select subnet → Actions → Edit subnet settings Tick Enable auto-assign public IPv4 address → Save.      2.3 Create EC2 ARM (AWS Graviton)  Go to EC2 → Launch Instance: https://console.aws.amazon.com/ec2/ Name: ec2-arm Select AMI: Amazon Linux 2 ARM 64-bit (Graviton). Select Instance Type: t4g.nano  Key pair: Choose or create a new one. Network settings:  VPC: Select workshop-vpc (or default VPC if using default). Subnet: Select workshop-subnet-public (or default subnet). Auto-assign Public IP: Enable. Security Group: Create new or reuse, open port 22 (SSH).   Click Launch Instance.    2.4 Create EC2 x86  Go to EC2 → Launch Instance. Name: ec2-x86 Select AMI: Amazon Linux 2 x86 64-bit. Select Instance Type: t3.micro  Key pair: Choose or create a new one. Network settings:  VPC: Select workshop-vpc. Subnet: Select workshop-subnet-public. Auto-assign Public IP: Enable. Security Group: Open port 22 (SSH).   Click Launch Instance.    2.5 Result You now have 2 instances:\n EC2 ARM: for ARM architecture testing. EC2 x86: for x86 architecture testing.   2.6 Manually create ECS Cluster on AWS Console  Go to Amazon ECS: https://console.aws.amazon.com/ecs/. Click Create Cluster. Cluster name: enter a name (e.g., MyManualEC2Cluster). In the Infrastructure section:  Select Amazon Fargate (serverless).   Leave other options as default → Create.   2.7 Install ECS Agent and register EC2 to Cluster Repeat the following steps for both EC2 ARM and EC2 x86.\nStep 1: SSH into EC2\nssh -i your-key.pem ec2-user@\u0026lt;Public_IP\u0026gt; Step 2: Install ECS Agent\nsudo amazon-linux-extras enable ecs sudo yum install -y ecs-init Step 3: Configure cluster name\necho \u0026#34;ECS_CLUSTER=MyManualEC2Cluster\u0026#34; | sudo tee -a /etc/ecs/ecs.config  Replace MyManualEC2Cluster with the cluster name you created.\n Step 4: Start ECS Agent\nsudo systemctl enable --now ecs  2.8 Verify EC2 joined the cluster  Go to AWS Console → ECS → Clusters → select MyManualEC2Cluster → ECS Instances tab. You will see 2 EC2 instances (ARM and x86) if the ECS Agent is running successfully.  Notes:\n EC2 must be attached to an IAM Role with AmazonEC2ContainerServiceforEC2Role permission. If not available:  Create a new role with the AmazonEC2ContainerServiceforEC2Role policy. Attach the role to EC2 via Actions → Security → Modify IAM Role.   The EC2 Security Group must open port 22 (SSH) and the service ports you want to run.  "},{"uri":"https://cerberasa.github.io/Workshop/clone/","title":"3. Prepare source code repository and Clone sample repo","tags":[],"description":"","content":"Objective Clone AWS\u0026rsquo;s sample repository to obtain the application source code and the multi-architecture CI/CD pipeline.\n 3.1 Clone the sample repository  Visit the repo link:\nhttps://github.com/aws-samples/aws-multiarch-container-build-pipeline   3.2 Check the repository structure   Clone the repo to your machine:\ngit clone https://github.com/aws-samples/aws-multiarch-container-build-pipeline.git cd aws-multiarch-container-build-pipeline   "},{"uri":"https://cerberasa.github.io/Workshop/cli-cdk/","title":"4. Install tools and configure AWS CLI, CDK","tags":[],"description":"","content":"Objective Install the AWS CLI, configure credentials, install Node.js/npm (if needed), and install the AWS CDK to prepare for deploying the pipeline with CDK.\n4.1 Install AWS CLI (AWS CLI v2) \u0026amp; verify macOS (Homebrew) brew install awscli Linux (x86_64) curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Linux (ARM aarch64) curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-aarch64.zip\u0026#34; -o \u0026#34;awscliv2_aarch64.zip\u0026#34; unzip awscliv2_aarch64.zip sudo ./aws/install Windows Download the MSI installer from: https://aws.amazon.com/cli/\nOr use Chocolatey:\nchoco install awscli Verify aws --version # e.g.: aws-cli/2.x.x Python/3.x ... 4.2 Configure AWS credentials (aws configure)  Security tip: Create a separate IAM user for the workshop with programmatic access. For a quick demo you can use AdministratorAccess, but in production prefer least-privilege.\n  Create an IAM User on the AWS Console https://aws.amazon.com/console/ → IAM → Users → Create user  Select Programmatic access\n Attach appropriate policy\n Save the Access Key ID and Secret Access Key    On your local machine (configure credentials):  aws configure # Enter in order: # AWS Access Key ID [None]: \u0026lt;ACCESS_KEY_ID\u0026gt; # AWS Secret Access Key [None]: \u0026lt;SECRET_ACCESS_KEY\u0026gt; # Default region name [None]: ap-southeast-1 # Default output format [None]: json Verify:  aws sts get-caller-identity # Returns: UserId, Account, Arn 4.3 Install AWS CDK \u0026amp; verify # Install CDK globally npm install -g aws-cdk # Verify version cdk --version 4.4 CDK bootstrap (prepare the environment) Run cdk bootstrap at least once per account/region so CDK can create the S3 bucket and other resources needed for deployment.\n# Set region if desired set AWS_REGION=ap-southeast-1 # Bootstrap environment (default) cdk bootstrap aws://%ACCOUNT_ID%/%AWS_REGION% "},{"uri":"https://cerberasa.github.io/Workshop/cdk-pipeline/","title":"5. Deploy the pipeline with CDK","tags":[],"description":"","content":"Objective Deploy the CDK stack to create the AWS services required for the pipeline, including:\n CodePipeline (automated build \u0026amp; deploy) CodeBuild (build multi-architecture images) ECR (Elastic Container Registry) (store images) IAM Roles \u0026amp; Policies (access for pipeline and build) S3 Bucket (store pipeline artifacts) KMS Key (encrypt the S3 bucket) ECS Cluster (run containers) CloudWatch Logs (store build and ECS logs) Security Groups (open ports for ECS if needed) CloudFormation Stacks (manage the entire infrastructure)   5.1 Set environment variables On Windows PowerShell:\n$env:CODESTAR_CONNECTION_ARN=\u0026#34;arn:aws:codestar-connections:ap-southeast-1:\u0026lt;account_id\u0026gt;:connection/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#34; $env:AWS_REGION=\u0026#34;ap-southeast-1\u0026#34; On macOS / Linux:\nexport CODESTAR_CONNECTION_ARN=\u0026#34;arn:aws:codestar-connections:ap-southeast-1:\u0026lt;account_id\u0026gt;:connection/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#34; export AWS_REGION=\u0026#34;ap-southeast-1\u0026#34;  5.2 Check synth before deploy Change into the cdk directory of the repo and install dependencies if needed:\ncd aws-multiarch-container-build-pipeline # if TypeScript npm install # or Python # python3 -m venv .venv # source .venv/bin/activate # pip install -r requirements.txt Run synth to validate the CloudFormation template:\ncdk synth If cdk synth succeeds, continue to deploy.\n 5.3 Run deploy # from the cdk directory cdk deploy MultiArchECSPipelineDemo  CDK will show changes and prompt for confirmation (y/n). The pipeline will automatically connect to GitHub via the CodeStar Connection you created. Note: During deployment, AWS will create all services listed in section 4.5, excluding ALB and EC2 (which were removed), so the cost will be lower.   5.4 Post-deploy checks  CodePipeline → check the pipeline and stage statuses. CodeBuild → check the project and logs (if the pipeline has triggered a build). ECR → check the repository (after the first build, images will appear). ECS → check the cluster \u0026amp; service. S3 Bucket → view pipeline artifacts. KMS Key → verify encryption.  "},{"uri":"https://cerberasa.github.io/Workshop/deploy/","title":"6. Deploy Application to EC2 ARM &amp; x86","tags":[],"description":"","content":"Objective Deploy the multi-architecture image from ECR and run the container on two EC2 instances (ARM Graviton and x86).\nIncludes: manual run, handling port conflicts, checking the container, opening Security Group ports, and keeping the container running stably.\n 6.1 Preparation on both EC2s  Docker installed (Amazon Linux 2 or Ubuntu). EC2 has outbound internet access or ECR access via VPC endpoint. EC2 has an IAM role allowing pull from ECR (ecr:GetAuthorizationToken, ecr:BatchGetImage, \u0026hellip;). Ensure Security Group opens port 80 or your desired public port (e.g., 8080).   6.2 Environment variables (on EC2 or local) export AWS_REGION=ap-southeast-1 export ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) export ECR_REPO=\u0026#34;$ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/multiarch-demo\u0026#34; export IMAGE_TAG=\u0026#34;latest\u0026#34;  6.3 Login to ECR aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com  6.4 Pull \u0026amp; run container 1. Stop old container if exists docker ps docker stop myapp || true docker rm myapp || true 2. Pull image docker pull $ECR_REPO:$IMAGE_TAG 3. Run container docker run -d --restart unless-stopped --name myapp -p 80:8080 $ECR_REPO:$IMAGE_TAG 4. If port is already in use error occurs docker: Error response from daemon: driver failed programming external connectivity on endpoint ... : Bind for 0.0.0.0:8080 failed: port is already allocated.\r=\u0026gt; How to fix:\nsudo netstat -tulpn | grep 8080 # Check process using the port docker stop \u0026lt;container_id\u0026gt; docker rm \u0026lt;container_id\u0026gt; # Or change port mapping docker run -d --restart unless-stopped --name myapp -p 8081:8080 $ECR_REPO:$IMAGE_TAG  6.5 Check container docker ps docker logs myapp --tail 50 docker exec -it myapp uname -m # Check architecture: aarch64 or x86_64  6.6 Open port on Security Group  Go to AWS Console → EC2 → Security Groups of the instance. Add inbound rule:  Type: HTTP (or Custom TCP) Port: 80 or 8080 Source: 0.0.0.0/0 (or your allowed IP)   Save and try accessing:  curl http://\u0026lt;EC2_PUBLIC_IP\u0026gt;:80  6.7 Deploy in parallel on ARM \u0026amp; x86  Run the above steps sequentially on each EC2.  Example:\nINSTANCE_IDS=\u0026#34;i-x86 i-arm\u0026#34; aws ssm send-command --instance-ids $INSTANCE_IDS --document-name \u0026#34;AWS-RunShellScript\u0026#34; --comment \u0026#34;Deploy multiarch\u0026#34; --parameters commands=\u0026#34;aws ecr get-login-password --region $AWS_REGION| docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com \u0026amp;\u0026amp; docker pull $ECR_REPO:$IMAGE_TAG\u0026amp;\u0026amp; docker stop myapp || true \u0026amp;\u0026amp; docker rm myapp || true \u0026amp;\u0026amp; docker run -d --restart unless-stopped --name myapp -p 80:8080 $ECR_REPO:$IMAGE_TAG\u0026#34; "},{"uri":"https://cerberasa.github.io/Workshop/cleanup/","title":"7. Cleanup resources","tags":[],"description":"","content":"Objective Quickly and safely clean up the resources created for the workshop to avoid unexpected costs.\n Before deleting: backup any important reports / logs. Confirm the correct account and region.\n  7.1 Check account \u0026amp; region aws sts get-caller-identity aws configure get region  7.2 Destroy with CDK cd aws-multiarch-container-build-pipeline/example/ecs-pipeline cdk list cdk destroy --all  CDK will delete resources following dependency order. If you encounter errors (for example an S3 bucket not empty), go to the CloudFormation Console -\u0026gt; Events to see details.   7.3 Stop / terminate EC2 instances 7.3 Delete S3 buckets 7.3 Delete ECR repositories 7.3 Delete IAM roles "},{"uri":"https://cerberasa.github.io/Workshop/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://cerberasa.github.io/Workshop/tags/","title":"Tags","tags":[],"description":"","content":""}]